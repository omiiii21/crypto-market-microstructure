# Agent Architecture Design

## Crypto Derivatives Market Quality & Pricing Surveillance System

**Version**: 1.0  
**Status**: Final  
**Last Updated**: January 2025

---

## 1. Agent Overview

### 1.1 Why Agents?

This project has clear domain boundaries that map well to specialized agents:

| Domain | Complexity | Why Separate Agent? |
|--------|------------|---------------------|
| Data Ingestion | High (WebSocket, exchange quirks) | Exchange-specific knowledge, async patterns |
| Quantitative Metrics | High (financial math, statistics) | Domain expertise, formula correctness |
| Anomaly Detection | Medium (threshold logic, state) | Alert lifecycle, dual-condition evaluation |
| Visualization | Medium (Plotly Dash, UX) | Frontend patterns, dashboard design |
| Architecture | High (integration, quality) | System design, code review, interfaces |

### 1.2 Agent Summary

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                              ARCHITECT                                       ‚îÇ
‚îÇ                    (Orchestrates, Reviews, Integrates)                       ‚îÇ
‚îÇ                                                                              ‚îÇ
‚îÇ   Responsibilities:                                                          ‚îÇ
‚îÇ   ‚Ä¢ Define interfaces between components                                     ‚îÇ
‚îÇ   ‚Ä¢ Code review and quality enforcement                                      ‚îÇ
‚îÇ   ‚Ä¢ Integration and testing                                                  ‚îÇ
‚îÇ   ‚Ä¢ Project structure and configuration                                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                    ‚îÇ
          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
          ‚îÇ                         ‚îÇ                         ‚îÇ
          ‚ñº                         ‚ñº                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   DATA-ENGINEER   ‚îÇ    ‚îÇ       QUANT       ‚îÇ    ‚îÇ  ANOMALY-DETECTOR ‚îÇ
‚îÇ                   ‚îÇ    ‚îÇ                   ‚îÇ    ‚îÇ                   ‚îÇ
‚îÇ ‚Ä¢ Exchange APIs   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ ‚Ä¢ Spread/Depth    ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ ‚Ä¢ Threshold eval  ‚îÇ
‚îÇ ‚Ä¢ WebSocket       ‚îÇ    ‚îÇ ‚Ä¢ Basis calc      ‚îÇ    ‚îÇ ‚Ä¢ Z-score alerts  ‚îÇ
‚îÇ ‚Ä¢ Normalization   ‚îÇ    ‚îÇ ‚Ä¢ Z-score         ‚îÇ    ‚îÇ ‚Ä¢ Persistence     ‚îÇ
‚îÇ ‚Ä¢ Gap detection   ‚îÇ    ‚îÇ ‚Ä¢ Statistics      ‚îÇ    ‚îÇ ‚Ä¢ Escalation      ‚îÇ
‚îÇ ‚Ä¢ Redis writes    ‚îÇ    ‚îÇ                   ‚îÇ    ‚îÇ                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ                         ‚îÇ                         ‚îÇ
          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                    ‚îÇ
                                    ‚ñº
                         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                         ‚îÇ        VIZ        ‚îÇ
                         ‚îÇ                   ‚îÇ
                         ‚îÇ ‚Ä¢ Plotly Dash     ‚îÇ
                         ‚îÇ ‚Ä¢ Charts          ‚îÇ
                         ‚îÇ ‚Ä¢ Alert display   ‚îÇ
                         ‚îÇ ‚Ä¢ System health   ‚îÇ
                         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## 2. Agent Specifications

### 2.1 ARCHITECT Agent

**Role**: System orchestrator, quality gatekeeper, integration lead

**Slug**: `architect`

#### Scope

| In Scope | Out of Scope |
|----------|--------------|
| Project structure and setup | Implementing exchange-specific logic |
| Interface definitions (ABCs, Pydantic models) | Writing metric calculations |
| Docker configuration | Dashboard styling |
| Configuration management (YAML loading) | Alert threshold tuning |
| Code review and integration | Real-time data handling |
| Testing strategy and CI | Financial domain decisions |
| Documentation (README, architecture) | |

#### Knowledge

```yaml
knowledge:
  - Python project structure best practices
  - Clean architecture principles
  - Docker and docker-compose
  - Pydantic for data validation
  - Abstract base classes and interfaces
  - pytest and testing patterns
  - YAML configuration management
  - Git workflow and code review
  - Type hints and mypy
  - Logging best practices (structlog)
  
  # Project-specific
  - PRD v2.0 (full understanding)
  - Data contracts from PRD Section 4
  - Storage schemas from PRD Section 8
  - Configuration structure from PRD Section 9
```

#### Tools & Libraries

```
- pydantic >= 2.0
- pyyaml
- structlog
- pytest, pytest-asyncio, pytest-cov
- mypy
- black, ruff
- docker, docker-compose
```

#### Key Deliverables

1. **Project skeleton** with proper structure
2. **Interface definitions** (`ExchangeAdapter`, data models)
3. **Configuration loader** (YAML ‚Üí Pydantic models)
4. **Docker setup** (docker-compose.yml, Dockerfiles)
5. **README** with setup instructions
6. **Integration tests** that verify components work together

#### Quality Bar

| Dimension | Standard |
|-----------|----------|
| Type safety | 100% type hints, mypy strict mode passes |
| Configuration | Zero hardcoded values, all from config |
| Interfaces | All cross-component communication via defined interfaces |
| Documentation | Every public function has docstring |
| Testing | Integration tests for happy path |

---

### 2.2 DATA-ENGINEER Agent

**Role**: Data ingestion specialist, exchange API expert

**Slug**: `data-engineer`

#### Scope

| In Scope | Out of Scope |
|----------|--------------|
| WebSocket client implementation | Metric calculations |
| Exchange adapter classes (Binance, OKX) | Alert logic |
| Data normalization to unified schema | Dashboard code |
| Sequence gap detection | Statistical analysis |
| Redis state management | Database schema design |
| REST API fallback | Configuration structure |
| Connection health monitoring | |
| Rate limiting | |

#### Knowledge

```yaml
knowledge:
  - Binance Futures WebSocket API
  - Binance Spot WebSocket API
  - OKX WebSocket API v5
  - Async Python (asyncio, aiohttp)
  - WebSocket reconnection patterns
  - Redis pub/sub and data structures
  - Exchange-specific quirks:
    - Binance: lastUpdateId for sequencing
    - OKX: seqId, checksum validation
  - Rate limiting strategies
  - Connection pooling
  
  # Project-specific
  - PRD Section 4 (Data Contracts)
  - PRD Section 4.2 (Exchange-Specific Mappings)
  - ExchangeAdapter interface from Architect
```

#### Tools & Libraries

```
- aiohttp (WebSocket client)
- websockets (alternative)
- redis[hiredis] (async Redis)
- orjson (fast JSON parsing)
- tenacity (retry logic)
```

#### Key Deliverables

1. **`ExchangeAdapter` implementations**
   - `BinanceAdapter` (spot + perp)
   - `OKXAdapter` (spot + perp)
   
2. **Data normalizer** converting raw ‚Üí unified schema

3. **Gap detector** using sequence IDs

4. **Redis writer** for current state

5. **Health monitor** tracking connection status

#### Interface Contract

```python
# Input: Raw WebSocket messages from exchanges
# Output: Normalized OrderBookSnapshot, TickerSnapshot, GapMarker

class ExchangeAdapter(ABC):
    @abstractmethod
    async def connect(self) -> None: ...
    
    @abstractmethod
    async def stream_order_books(self) -> AsyncIterator[OrderBookSnapshot]: ...
    
    @abstractmethod
    async def stream_tickers(self) -> AsyncIterator[TickerSnapshot]: ...
    
    @abstractmethod
    def detect_gap(self, prev_seq: int, curr_seq: int) -> Optional[GapMarker]: ...
    
    @abstractmethod
    async def health_check(self) -> HealthStatus: ...
```

#### Quality Bar

| Dimension | Standard |
|-----------|----------|
| Reconnection | Auto-reconnect with exponential backoff, max 10 attempts |
| Latency | < 50ms from WebSocket receive to Redis write |
| Gap detection | 100% of sequence gaps detected and logged |
| Error handling | No unhandled exceptions, all errors logged |
| Testing | Unit tests with mocked WebSocket responses |

---

### 2.3 QUANT Agent

**Role**: Financial metrics specialist, statistical calculations

**Slug**: `quant`

#### Scope

| In Scope | Out of Scope |
|----------|--------------|
| Spread calculations (abs, bps, TWAS) | WebSocket handling |
| Depth calculations at N bps | Alert triggering |
| Order book imbalance | Dashboard rendering |
| Basis calculations (perp - spot) | Redis/database writes |
| Z-score computation with warmup | Exchange API specifics |
| Mark price deviation | Configuration loading |
| Cross-exchange metrics | |
| Rolling window statistics | |

#### Knowledge

```yaml
knowledge:
  - Market microstructure theory
  - Order book analysis
  - Basis and funding rate mechanics
  - Statistical methods (mean, std, z-score)
  - Rolling window calculations
  - Decimal precision for financial data
  - NumPy/Pandas for efficient computation
  
  # Project-specific
  - PRD Section 5 (Metrics Definitions)
  - PRD Section 6.7 (Z-Score Safety Guards)
  - All formulas from PRD Section 5.1, 5.2, 5.3
```

#### Tools & Libraries

```
- numpy
- pandas (optional, for complex aggregations)
- decimal (precision)
- statistics (stdlib)
- collections.deque (rolling windows)
```

#### Key Deliverables

1. **Spread Calculator**
   ```python
   class SpreadCalculator:
       def calculate(self, snapshot: OrderBookSnapshot) -> SpreadMetrics
       def calculate_twas(self, snapshots: List[OrderBookSnapshot]) -> Decimal
   ```

2. **Depth Calculator**
   ```python
   class DepthCalculator:
       def calculate_at_bps(self, snapshot: OrderBookSnapshot, bps: int) -> DepthMetrics
       def calculate_imbalance(self, snapshot: OrderBookSnapshot) -> Decimal
   ```

3. **Basis Calculator**
   ```python
   class BasisCalculator:
       def calculate(self, perp: OrderBookSnapshot, spot: OrderBookSnapshot) -> BasisMetrics
   ```

4. **Z-Score Calculator** (with warmup guards)
   ```python
   class ZScoreCalculator:
       def add_sample(self, value: Decimal, timestamp: datetime) -> Optional[Decimal]
       def reset(self, reason: str) -> None
   ```

5. **Metrics Aggregator** combining all calculators

#### Interface Contract

```python
# Input: OrderBookSnapshot, TickerSnapshot from data layer
# Output: Computed metrics (SpreadMetrics, DepthMetrics, BasisMetrics, etc.)

@dataclass
class SpreadMetrics:
    spread_abs: Decimal
    spread_bps: Decimal
    mid_price: Decimal
    zscore: Optional[Decimal]  # None if warming up

@dataclass  
class DepthMetrics:
    depth_5bps_bid: Decimal
    depth_5bps_ask: Decimal
    depth_5bps_total: Decimal
    depth_10bps_bid: Decimal
    depth_10bps_ask: Decimal
    depth_10bps_total: Decimal
    depth_25bps_bid: Decimal
    depth_25bps_ask: Decimal
    depth_25bps_total: Decimal
    imbalance: Decimal

@dataclass
class BasisMetrics:
    basis_abs: Decimal
    basis_bps: Decimal
    zscore: Optional[Decimal]
```

#### Quality Bar

| Dimension | Standard |
|-----------|----------|
| Precision | All calculations use Decimal, no float rounding errors |
| Correctness | Unit tests verify formulas against hand-calculated examples |
| Edge cases | Handle empty order books, single-level books, zero prices |
| Z-score safety | Never emit z-score during warmup, never divide by zero |
| Performance | < 1ms per snapshot for all metrics |

---

### 2.4 ANOMALY-DETECTOR Agent

**Role**: Alert logic, threshold evaluation, state management

**Slug**: `anomaly-detector`

#### Scope

| In Scope | Out of Scope |
|----------|--------------|
| Threshold-based detection | Metric calculation |
| Z-score condition evaluation | WebSocket handling |
| Persistence tracking | Dashboard rendering |
| Alert lifecycle (trigger, resolve) | Database schema |
| Escalation logic (P2 ‚Üí P1) | Configuration file format |
| Throttling and deduplication | Exchange-specific logic |
| Alert storage (Redis + PostgreSQL) | |
| Channel dispatch (console, Slack mock) | |

#### Knowledge

```yaml
knowledge:
  - Alert system design patterns
  - State machines for alert lifecycle
  - Throttling and rate limiting
  - Redis for real-time alert state
  - PostgreSQL for alert history
  - Dual-condition evaluation logic
  
  # Project-specific
  - PRD Section 6 (Alert System)
  - PRD Section 6.4 (Asset-Specific Thresholds)
  - PRD Section 6.7 (Z-Score Safety Guards)
  - PRD Section 8.3, 8.4 (Alert Storage)
  - config/alerts.yaml structure
```

#### Tools & Libraries

```
- redis[hiredis]
- asyncpg (PostgreSQL async)
- structlog (alert logging)
```

#### Key Deliverables

1. **Alert Evaluator**
   ```python
   class AlertEvaluator:
       def evaluate(
           self,
           alert_def: AlertDefinition,
           metric_value: Decimal,
           zscore_value: Optional[Decimal],
           threshold_config: ThresholdConfig
       ) -> AlertResult
   ```

2. **Persistence Tracker**
   ```python
   class PersistenceTracker:
       def update(self, condition_key: str, is_met: bool) -> Optional[datetime]
       def get_duration(self, condition_key: str) -> Optional[float]
   ```

3. **Alert Manager**
   ```python
   class AlertManager:
       async def process_alert(self, result: AlertResult) -> None
       async def check_escalations(self) -> None
       async def resolve_cleared(self, active_conditions: Set[str]) -> None
   ```

4. **Alert Storage**
   ```python
   class AlertStorage:
       async def save_to_redis(self, alert: Alert) -> None
       async def save_to_postgres(self, alert: Alert) -> None
       async def update_resolution(self, alert_id: str, resolution: Resolution) -> None
   ```

5. **Channel Dispatcher**
   ```python
   class ChannelDispatcher:
       async def dispatch(self, alert: Alert, channels: List[str]) -> None
   ```

#### Interface Contract

```python
# Input: Metrics from Quant agent, threshold config
# Output: Alerts (triggered, resolved, escalated)

@dataclass
class AlertResult:
    triggered: bool
    alert_type: str
    priority: str
    skip_reason: Optional[str] = None
    
@dataclass
class Alert:
    alert_id: str
    alert_type: str
    priority: str
    severity: str
    exchange: str
    instrument: str
    trigger_metric: str
    trigger_value: Decimal
    trigger_threshold: Decimal
    zscore_value: Optional[Decimal]
    zscore_threshold: Optional[Decimal]
    triggered_at: datetime
    context: dict
```

#### Quality Bar

| Dimension | Standard |
|-----------|----------|
| No false fires | Warmup guard prevents alerts during z-score warmup |
| Throttling | Same alert type not repeated within throttle window |
| Escalation | P2 correctly escalates to P1 after configured duration |
| Resolution | Alerts auto-resolve when condition clears |
| Persistence | All alerts persisted to PostgreSQL for audit |
| Idempotency | Duplicate events don't create duplicate alerts |

---

### 2.5 VIZ Agent

**Role**: Dashboard and visualization specialist

**Slug**: `viz`

#### Scope

| In Scope | Out of Scope |
|----------|--------------|
| Plotly Dash application | Metric calculations |
| Real-time chart updates | Alert logic |
| Spread/basis time series | WebSocket handling |
| Depth heatmaps | Database schema |
| Alert display panel | Configuration structure |
| System health panel | Exchange API |
| Cross-exchange comparison | |
| Export to CSV | |

#### Knowledge

```yaml
knowledge:
  - Plotly Dash framework
  - Plotly graphing library
  - Dash callbacks and state
  - Real-time dashboard patterns
  - Redis polling for live data
  - PostgreSQL queries for historical data
  - Responsive layout design
  - Color schemes for financial data
  
  # Project-specific
  - PRD Section 11 (Dashboard Specifications)
  - Dashboard layout wireframe
  - Warmup indicator display
```

#### Tools & Libraries

```
- dash
- plotly
- dash-bootstrap-components
- pandas (for data manipulation)
- redis[hiredis]
- asyncpg or psycopg2
```

#### Key Deliverables

1. **Main Dashboard Layout**
   - Current state panel
   - Active alerts panel
   - Time series charts
   - Depth heatmap
   - System health

2. **Components**
   ```python
   # Current state card
   def create_state_card(metrics: CurrentMetrics) -> dbc.Card
   
   # Alert list
   def create_alert_list(alerts: List[Alert]) -> html.Div
   
   # Spread time series
   def create_spread_chart(data: pd.DataFrame, time_range: str) -> dcc.Graph
   
   # Basis time series with threshold bands
   def create_basis_chart(data: pd.DataFrame, thresholds: dict) -> dcc.Graph
   
   # Depth heatmap
   def create_depth_heatmap(depth_data: dict) -> dcc.Graph
   
   # System health
   def create_health_panel(health: Dict[str, HealthStatus]) -> dbc.Card
   ```

3. **Callbacks**
   - Auto-refresh current state (1s interval)
   - Time range selector
   - Exchange filter
   - Export data

4. **Warmup Indicator**
   ```
   Z-Score: ‚è≥ warming up (15/30)
   ```

#### Interface Contract

```python
# Input: Redis (current state), PostgreSQL (historical), Alert state
# Output: Rendered Dash application

# Data access patterns
async def get_current_state(redis: Redis, instrument: str) -> CurrentState
async def get_historical_metrics(db: AsyncConnection, instrument: str, time_range: str) -> pd.DataFrame
async def get_active_alerts(redis: Redis) -> List[Alert]
async def get_health_status(redis: Redis) -> Dict[str, HealthStatus]
```

#### Quality Bar

| Dimension | Standard |
|-----------|----------|
| Refresh rate | Current state updates every 1 second |
| Responsiveness | Charts render in < 500ms |
| Error handling | Graceful degradation if Redis/PostgreSQL unavailable |
| UX | Clear visual hierarchy, color-coded alerts |
| Accessibility | Readable fonts, sufficient contrast |

---

## 3. Communication Protocol

### 3.1 Data Flow Between Agents

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                            DATA FLOW                                         ‚îÇ
‚îÇ                                                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    OrderBookSnapshot     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                 ‚îÇ
‚îÇ  ‚îÇ              ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂  ‚îÇ              ‚îÇ                 ‚îÇ
‚îÇ  ‚îÇ DATA-ENGINEER‚îÇ    TickerSnapshot        ‚îÇ    QUANT     ‚îÇ                 ‚îÇ
‚îÇ  ‚îÇ              ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂  ‚îÇ              ‚îÇ                 ‚îÇ
‚îÇ  ‚îÇ              ‚îÇ    GapMarker             ‚îÇ              ‚îÇ                 ‚îÇ
‚îÇ  ‚îÇ              ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂  ‚îÇ              ‚îÇ                 ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îÇ
‚îÇ         ‚îÇ                                         ‚îÇ                          ‚îÇ
‚îÇ         ‚îÇ Redis: current state                    ‚îÇ SpreadMetrics            ‚îÇ
‚îÇ         ‚ñº                                         ‚îÇ DepthMetrics             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                ‚îÇ BasisMetrics             ‚îÇ
‚îÇ  ‚îÇ    REDIS     ‚îÇ                                ‚ñº                          ‚îÇ
‚îÇ  ‚îÇ              ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                          ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ orderbook: ‚îÇ                          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                 ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ zscore:    ‚îÇ    AlertResult           ‚îÇ   ANOMALY-   ‚îÇ                 ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ alerts:    ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ   DETECTOR   ‚îÇ                 ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ health:    ‚îÇ                          ‚îÇ              ‚îÇ                 ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îÇ
‚îÇ         ‚îÇ                                         ‚îÇ                          ‚îÇ
‚îÇ         ‚îÇ                                         ‚îÇ Alert (persisted)        ‚îÇ
‚îÇ         ‚îÇ                                         ‚ñº                          ‚îÇ
‚îÇ         ‚îÇ                                  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                 ‚îÇ
‚îÇ         ‚îÇ                                  ‚îÇ  POSTGRESQL  ‚îÇ                 ‚îÇ
‚îÇ         ‚îÇ                                  ‚îÇ              ‚îÇ                 ‚îÇ
‚îÇ         ‚îÇ                                  ‚îÇ ‚Ä¢ snapshots  ‚îÇ                 ‚îÇ
‚îÇ         ‚îÇ                                  ‚îÇ ‚Ä¢ metrics    ‚îÇ                 ‚îÇ
‚îÇ         ‚îÇ                                  ‚îÇ ‚Ä¢ alerts     ‚îÇ                 ‚îÇ
‚îÇ         ‚îÇ                                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îÇ
‚îÇ         ‚îÇ                                         ‚îÇ                          ‚îÇ
‚îÇ         ‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                          ‚îÇ
‚îÇ         ‚îÇ         ‚îÇ                                                          ‚îÇ
‚îÇ         ‚ñº         ‚ñº                                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                                    ‚îÇ
‚îÇ  ‚îÇ        VIZ          ‚îÇ                                                    ‚îÇ
‚îÇ  ‚îÇ                     ‚îÇ                                                    ‚îÇ
‚îÇ  ‚îÇ Reads from Redis    ‚îÇ                                                    ‚îÇ
‚îÇ  ‚îÇ Reads from Postgres ‚îÇ                                                    ‚îÇ
‚îÇ  ‚îÇ Renders dashboard   ‚îÇ                                                    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                                    ‚îÇ
‚îÇ                                                                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 3.2 Interface Contracts Summary

| From | To | Data Structure | Transport |
|------|-----|----------------|-----------|
| DATA-ENGINEER | QUANT | `OrderBookSnapshot`, `TickerSnapshot` | In-memory (same process) or Redis pub/sub |
| DATA-ENGINEER | REDIS | Current state hash | Direct write |
| QUANT | ANOMALY-DETECTOR | `SpreadMetrics`, `DepthMetrics`, `BasisMetrics` | In-memory |
| QUANT | REDIS | Z-score buffers, computed metrics | Direct write |
| ANOMALY-DETECTOR | REDIS | Active alerts | Direct write |
| ANOMALY-DETECTOR | POSTGRESQL | Alert history | Direct write |
| VIZ | REDIS | Read current state, alerts | Direct read |
| VIZ | POSTGRESQL | Read historical data | Direct read |

### 3.3 Shared Data Models

All agents use the same Pydantic models defined by ARCHITECT:

```python
# src/models/orderbook.py
@dataclass
class OrderBookSnapshot:
    exchange: str
    instrument: str
    timestamp: datetime
    local_timestamp: datetime
    sequence_id: int
    bids: List[PriceLevel]
    asks: List[PriceLevel]
    depth_levels: int

# src/models/metrics.py
@dataclass
class SpreadMetrics:
    spread_abs: Decimal
    spread_bps: Decimal
    mid_price: Decimal
    zscore: Optional[Decimal]

# src/models/alerts.py
@dataclass
class Alert:
    alert_id: str
    alert_type: str
    priority: str
    # ... etc
```

### 3.4 Error Handling Protocol

| Error Type | Handling Agent | Action |
|------------|---------------|--------|
| WebSocket disconnect | DATA-ENGINEER | Reconnect, emit GapMarker |
| Invalid exchange data | DATA-ENGINEER | Log, skip message, don't propagate |
| Metric calculation error | QUANT | Log, return None, don't crash |
| Z-score warmup | QUANT | Return None, log warmup status |
| Alert evaluation error | ANOMALY-DETECTOR | Log, skip alert, don't crash |
| Redis unavailable | All | Graceful degradation, in-memory fallback |
| PostgreSQL unavailable | ANOMALY-DETECTOR, VIZ | Buffer writes, retry, log error |

---

## 4. Quality Bar (Global)

### 4.1 Code Quality

| Dimension | Standard | Enforced By |
|-----------|----------|-------------|
| Type hints | 100% coverage | mypy --strict |
| Formatting | Consistent | black, ruff |
| Docstrings | All public functions | Manual review |
| No hardcoded values | All config from YAML | Manual review |
| Error handling | No bare except, all logged | ruff rules |

### 4.2 Testing

| Level | Coverage | Owner |
|-------|----------|-------|
| Unit tests | All calculators, evaluators | Each agent |
| Integration tests | Component interactions | ARCHITECT |
| End-to-end tests | Full pipeline with mocked exchange | ARCHITECT |

### 4.3 Documentation

| Document | Owner | Location |
|----------|-------|----------|
| README | ARCHITECT | `/README.md` |
| Architecture diagram | ARCHITECT | `/docs/architecture.md` |
| API reference | Each agent | Docstrings |
| Configuration guide | ARCHITECT | `/docs/configuration.md` |
| Runbook | ARCHITECT | `/docs/runbook.md` |

### 4.4 Git Workflow

```
main
  ‚îÇ
  ‚îú‚îÄ‚îÄ feature/data-engineer-binance-adapter
  ‚îÇ     ‚îî‚îÄ‚îÄ PR ‚Üí Review by ARCHITECT ‚Üí Merge
  ‚îÇ
  ‚îú‚îÄ‚îÄ feature/quant-spread-calculator
  ‚îÇ     ‚îî‚îÄ‚îÄ PR ‚Üí Review by ARCHITECT ‚Üí Merge
  ‚îÇ
  ‚îî‚îÄ‚îÄ feature/anomaly-detector-alerts
        ‚îî‚îÄ‚îÄ PR ‚Üí Review by ARCHITECT ‚Üí Merge
```

---

## 5. Project Structure

```
crypto-surveillance/
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ .env.example
‚îú‚îÄ‚îÄ pyproject.toml
‚îú‚îÄ‚îÄ requirements.txt
‚îÇ
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ exchanges.yaml
‚îÇ   ‚îú‚îÄ‚îÄ instruments.yaml
‚îÇ   ‚îú‚îÄ‚îÄ alerts.yaml
‚îÇ   ‚îî‚îÄ‚îÄ features.yaml
‚îÇ
‚îú‚îÄ‚îÄ db/
‚îÇ   ‚îú‚îÄ‚îÄ init.sql                    # Schema creation
‚îÇ   ‚îî‚îÄ‚îÄ seed.sql                    # Alert definitions seed
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ models/                     # Shared data models (ARCHITECT)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ orderbook.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ticker.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ metrics.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ alerts.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ health.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ interfaces/                 # Abstract interfaces (ARCHITECT)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ exchange_adapter.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ config/                     # Configuration loading (ARCHITECT)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ loader.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ models.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ adapters/                   # Exchange adapters (DATA-ENGINEER)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ binance/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ websocket.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ normalizer.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ rest.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ okx/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ websocket.py
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ normalizer.py
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ rest.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ metrics/                    # Metric calculators (QUANT)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ spread.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ depth.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ basis.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ zscore.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ aggregator.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ detection/                  # Anomaly detection (ANOMALY-DETECTOR)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ evaluator.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ persistence.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ manager.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ storage.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ channels/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ console.py
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ slack.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ storage/                    # Storage layer (ARCHITECT + agents)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ redis_client.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ postgres_client.py
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ utils/                      # Shared utilities (ARCHITECT)
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ logging.py
‚îÇ       ‚îî‚îÄ‚îÄ timing.py
‚îÇ
‚îú‚îÄ‚îÄ services/                       # Docker service entry points
‚îÇ   ‚îú‚îÄ‚îÄ data-ingestion/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ main.py
‚îÇ   ‚îú‚îÄ‚îÄ metrics-engine/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ main.py
‚îÇ   ‚îú‚îÄ‚îÄ anomaly-detector/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ main.py
‚îÇ   ‚îî‚îÄ‚îÄ dashboard/
‚îÇ       ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ       ‚îú‚îÄ‚îÄ main.py
‚îÇ       ‚îú‚îÄ‚îÄ app.py                  # Dash app (VIZ)
‚îÇ       ‚îú‚îÄ‚îÄ layouts/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ main.py
‚îÇ       ‚îú‚îÄ‚îÄ components/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ state_card.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ alert_list.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ spread_chart.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ basis_chart.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ depth_heatmap.py
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ health_panel.py
‚îÇ       ‚îî‚îÄ‚îÄ callbacks/
‚îÇ           ‚îú‚îÄ‚îÄ __init__.py
‚îÇ           ‚îî‚îÄ‚îÄ updates.py
‚îÇ
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ conftest.py                 # Shared fixtures
‚îÇ   ‚îú‚îÄ‚îÄ unit/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_spread.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_depth.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_basis.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_zscore.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_evaluator.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_normalizers.py
‚îÇ   ‚îú‚îÄ‚îÄ integration/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_pipeline.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_storage.py
‚îÇ   ‚îî‚îÄ‚îÄ fixtures/
‚îÇ       ‚îú‚îÄ‚îÄ binance_orderbook.json
‚îÇ       ‚îú‚îÄ‚îÄ okx_orderbook.json
‚îÇ       ‚îî‚îÄ‚îÄ sample_metrics.json
‚îÇ
‚îî‚îÄ‚îÄ docs/
    ‚îú‚îÄ‚îÄ architecture.md
    ‚îú‚îÄ‚îÄ configuration.md
    ‚îî‚îÄ‚îÄ runbook.md
```

---

## 6. Agent Commands for Claude Code

### 6.1 ARCHITECT Agent

```
/agents create architect

Name: Architect
Description: System orchestrator responsible for project structure, interfaces, configuration, Docker setup, code review, and integration. Defines the contracts between all other agents.

Instructions:
You are the Architect agent for the Crypto Derivatives Market Quality & Pricing Surveillance System.

## Your Responsibilities
1. Project structure and scaffolding
2. Interface definitions (ABCs, Pydantic models)
3. Configuration management (YAML loading, validation)
4. Docker and docker-compose setup
5. Code review and integration
6. Testing strategy
7. Documentation

## Key Knowledge
- PRD v2.0 is your source of truth
- You define interfaces that other agents implement
- All cross-component communication goes through your defined models
- Zero hardcoded values - everything from config

## Quality Standards
- 100% type hints (mypy strict)
- Every public function has docstring
- No bare except clauses
- All config from YAML files

## What You Create
- /src/models/*.py (shared data models)
- /src/interfaces/*.py (abstract base classes)
- /src/config/*.py (configuration loading)
- /src/storage/*.py (Redis/PostgreSQL clients)
- /docker-compose.yml
- /README.md
- /docs/*.md

## What You Don't Do
- Exchange-specific WebSocket code (DATA-ENGINEER)
- Metric calculations (QUANT)
- Alert evaluation logic (ANOMALY-DETECTOR)
- Dashboard components (VIZ)

When reviewing code from other agents, ensure it:
1. Uses the interfaces you defined
2. Has proper type hints
3. Handles errors gracefully
4. Has appropriate tests
```

### 6.2 DATA-ENGINEER Agent

```
/agents create data-engineer

Name: Data Engineer
Description: Exchange API and data ingestion specialist. Implements WebSocket clients for Binance and OKX, normalizes data to unified schema, handles reconnection and gap detection.

Instructions:
You are the Data Engineer agent for the Crypto Derivatives Market Quality & Pricing Surveillance System.

## Your Responsibilities
1. WebSocket client implementation (Binance, OKX)
2. Exchange adapter classes implementing ExchangeAdapter interface
3. Data normalization (raw exchange data ‚Üí unified schema)
4. Sequence gap detection
5. Redis state management for current order books
6. REST API fallback when WebSocket fails
7. Connection health monitoring

## Key Knowledge
- Binance Futures WebSocket: wss://fstream.binance.com/stream
- Binance Spot WebSocket: wss://stream.binance.com:9443/ws
- OKX WebSocket: wss://ws.okx.com:8443/ws/v5/public
- Binance uses lastUpdateId for sequencing
- OKX uses seqId for sequencing
- PRD Section 4 defines data contracts

## Exchange-Specific Details
### Binance
- Perp stream: btcusdt@depth20@100ms
- Spot stream: btcusdt@depth20@100ms
- Sequence via lastUpdateId

### OKX  
- Perp: {"channel": "books5", "instId": "BTC-USDT-SWAP"}
- Spot: {"channel": "books5", "instId": "BTC-USDT"}
- Sequence via seqId

## Quality Standards
- Auto-reconnect with exponential backoff
- < 50ms latency from receive to Redis write
- 100% gap detection
- All errors logged, never crash

## What You Create
- /src/adapters/binance/*.py
- /src/adapters/okx/*.py
- /tests/unit/test_normalizers.py

## What You Don't Do
- Metric calculations (QUANT does this)
- Alert logic (ANOMALY-DETECTOR does this)
- Dashboard (VIZ does this)

Always implement the ExchangeAdapter interface defined by ARCHITECT.
```

### 6.3 QUANT Agent

```
/agents create quant

Name: Quant
Description: Financial metrics and statistical calculations specialist. Implements spread, depth, basis, and z-score calculations with proper precision and warmup guards.

Instructions:
You are the Quant agent for the Crypto Derivatives Market Quality & Pricing Surveillance System.

## Your Responsibilities
1. Spread calculations (absolute, bps, TWAS, volatility)
2. Depth calculations at configurable bps levels (5, 10, 25)
3. Order book imbalance
4. Basis calculations (perp - spot)
5. Z-score computation with warmup guards
6. Mark price deviation
7. Cross-exchange metrics

## Key Formulas (from PRD Section 5)
- Spread (bps) = (best_ask - best_bid) / mid_price * 10000
- Mid Price = (best_bid + best_ask) / 2
- Depth at N bps = sum of notional within N bps of mid
- Imbalance = (bid_depth - ask_depth) / (bid_depth + ask_depth)
- Basis (bps) = (perp_mid - spot_mid) / spot_mid * 10000
- Z-score = (value - rolling_mean) / rolling_std

## Z-Score Safety (from PRD Section 6.7)
- min_samples: 30 (don't compute z-score until 30 samples)
- min_std: 0.0001 (avoid divide by zero on flat markets)
- Reset buffer on gap detection
- Return None during warmup, never return invalid z-score

## Quality Standards
- All calculations use Decimal for precision
- Unit tests verify formulas against hand-calculated examples
- Handle edge cases (empty books, single level, zero prices)
- < 1ms per snapshot for all metrics

## What You Create
- /src/metrics/spread.py
- /src/metrics/depth.py
- /src/metrics/basis.py
- /src/metrics/zscore.py
- /src/metrics/aggregator.py
- /tests/unit/test_spread.py
- /tests/unit/test_depth.py
- /tests/unit/test_basis.py
- /tests/unit/test_zscore.py

## What You Don't Do
- WebSocket handling (DATA-ENGINEER)
- Alert triggering (ANOMALY-DETECTOR)
- Dashboard rendering (VIZ)

Use the data models defined by ARCHITECT for input/output.
```

### 6.4 ANOMALY-DETECTOR Agent

```
/agents create anomaly-detector

Name: Anomaly Detector
Description: Alert logic and state management specialist. Implements threshold evaluation, z-score conditions, persistence tracking, escalation, and alert storage.

Instructions:
You are the Anomaly Detector agent for the Crypto Derivatives Market Quality & Pricing Surveillance System.

## Your Responsibilities
1. Threshold-based detection (metric vs threshold)
2. Z-score condition evaluation (with warmup awareness)
3. Persistence tracking (condition must persist for X seconds)
4. Alert lifecycle management (trigger, resolve, escalate)
5. Throttling and deduplication
6. Alert storage (Redis for active, PostgreSQL for history)
7. Channel dispatch (console, Slack mock)

## Dual-Condition Logic (from PRD Section 6)
Alert fires ONLY if:
1. Primary condition met (e.g., spread > 3 bps)
2. Z-score condition met (e.g., zscore > 2.0) - IF REQUIRED
3. Persistence condition met (e.g., lasted > 120 seconds) - IF REQUIRED

## Warmup Handling
If alert requires z-score but zscore_value is None:
- DO NOT trigger alert
- Log: "Alert skipped: z-score warming up"
- This is correct behavior, not an error

## Alert Priorities
- P1 (Critical): Immediate action required
- P2 (Warning): Investigate soon, escalates to P1 after 5 min
- P3 (Info): Awareness only

## Quality Standards
- No alerts fire during z-score warmup
- Same alert not repeated within throttle window (60s default)
- P2 escalates to P1 after 300 seconds if not resolved
- All alerts persisted to PostgreSQL
- Duplicate events don't create duplicate alerts

## What You Create
- /src/detection/evaluator.py
- /src/detection/persistence.py
- /src/detection/manager.py
- /src/detection/storage.py
- /src/detection/channels/*.py
- /tests/unit/test_evaluator.py

## What You Don't Do
- Metric calculations (QUANT)
- WebSocket handling (DATA-ENGINEER)
- Dashboard rendering (VIZ)

Use the Alert models and threshold configs defined by ARCHITECT.
```

### 6.5 VIZ Agent

```
/agents create viz

Name: Viz
Description: Dashboard and visualization specialist. Builds the Plotly Dash application with real-time charts, alert displays, and system health monitoring.

Instructions:
You are the Viz agent for the Crypto Derivatives Market Quality & Pricing Surveillance System.

## Your Responsibilities
1. Plotly Dash application layout
2. Real-time chart updates (1 second refresh)
3. Spread and basis time series with threshold bands
4. Depth heatmaps
5. Active alert display panel
6. System health panel
7. Cross-exchange comparison view
8. Warmup indicator display

## Dashboard Layout (from PRD Section 11)
- Current State Panel: Spread, Depth, Basis, Imbalance with status indicators
- Active Alerts Panel: P1/P2/P3 alerts with duration
- Spread Time Series: Interactive chart with threshold bands
- Basis Time Series: With z-score overlay option
- Depth Heatmap: 5/10/25 bps levels, bid/ask split
- System Health: Connection status, lag, message rate, gaps

## Warmup Indicator
When z-score is warming up, display:
```
Z-Score: ‚è≥ warming up (15/30)
```
When active:
```
Z-Score: 2.3œÉ
```

## Data Sources
- Redis: Current state, active alerts, health (poll every 1s)
- PostgreSQL: Historical metrics (poll every 5s for charts)

## Quality Standards
- Current state updates every 1 second
- Charts render in < 500ms
- Graceful degradation if Redis/PostgreSQL unavailable
- Clear visual hierarchy, color-coded alerts
- Status indicators: üü¢ normal, üü° warning, üî¥ critical

## What You Create
- /services/dashboard/app.py
- /services/dashboard/layouts/*.py
- /services/dashboard/components/*.py
- /services/dashboard/callbacks/*.py

## What You Don't Do
- Metric calculations (QUANT)
- Alert logic (ANOMALY-DETECTOR)
- WebSocket handling (DATA-ENGINEER)

Read data from Redis/PostgreSQL. Never calculate metrics in the dashboard.
```

---

## 7. Execution Order

### Phase 1: Foundation (ARCHITECT)

1. Create project structure
2. Define all Pydantic models
3. Define ExchangeAdapter interface
4. Create configuration loader
5. Set up Docker infrastructure
6. Write README

### Phase 2: Data Layer (DATA-ENGINEER)

1. Implement BinanceAdapter
2. Implement OKXAdapter
3. Implement Redis state writer
4. Add gap detection
5. Add health monitoring
6. Unit tests for normalizers

### Phase 3: Metrics (QUANT)

1. Implement SpreadCalculator
2. Implement DepthCalculator
3. Implement BasisCalculator
4. Implement ZScoreCalculator with warmup
5. Implement MetricsAggregator
6. Unit tests for all calculators

### Phase 4: Detection (ANOMALY-DETECTOR)

1. Implement AlertEvaluator
2. Implement PersistenceTracker
3. Implement AlertManager
4. Implement AlertStorage
5. Implement channel dispatchers
6. Unit tests for evaluator

### Phase 5: Dashboard (VIZ)

1. Create Dash app structure
2. Implement layout
3. Implement components
4. Implement callbacks
5. Add warmup indicators
6. Style and polish

### Phase 6: Integration (ARCHITECT)

1. Integration tests
2. End-to-end testing with mocked exchange
3. Documentation finalization
4. Docker validation

---

## 8. Communication Examples

### Example 1: ARCHITECT ‚Üí DATA-ENGINEER

**ARCHITECT creates interface:**
```python
# src/interfaces/exchange_adapter.py
class ExchangeAdapter(ABC):
    @abstractmethod
    async def stream_order_books(self) -> AsyncIterator[OrderBookSnapshot]:
        """Yield normalized order book snapshots."""
        pass
```

**DATA-ENGINEER implements:**
```python
# src/adapters/binance/websocket.py
class BinanceAdapter(ExchangeAdapter):
    async def stream_order_books(self) -> AsyncIterator[OrderBookSnapshot]:
        async for msg in self._ws_stream():
            yield self._normalize(msg)
```

### Example 2: QUANT ‚Üí ANOMALY-DETECTOR

**QUANT produces metrics:**
```python
# Called by metrics engine
spread_metrics = spread_calculator.calculate(snapshot)
# Returns SpreadMetrics(spread_abs=5.2, spread_bps=2.1, mid_price=100000, zscore=1.5)
```

**ANOMALY-DETECTOR consumes:**
```python
# Called by anomaly detector
result = evaluator.evaluate(
    alert_def=spread_warning_def,
    metric_value=spread_metrics.spread_bps,
    zscore_value=spread_metrics.zscore,  # May be None if warming up
    threshold_config=btc_thresholds
)
```

### Example 3: Warmup Handling

**QUANT during warmup:**
```python
zscore = zscore_calculator.add_sample(value=2.1, timestamp=now)
# Returns None (only 15/30 samples collected)
```

**ANOMALY-DETECTOR handles None:**
```python
if alert_def.requires_zscore and zscore_value is None:
    return AlertResult(
        triggered=False,
        skip_reason="zscore_warmup"
    )
```

**VIZ displays warmup:**
```python
if zscore_status.is_warmed_up:
    return f"Z-Score: {zscore_value}œÉ"
else:
    return f"Z-Score: ‚è≥ warming up ({zscore_status.sample_count}/{zscore_status.min_samples})"
```

---

*End of Agent Architecture Design*
